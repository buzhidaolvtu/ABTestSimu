import streamlit as st
import numpy as np
import pandas as pd
import hashlib
from statsmodels.stats.proportion import proportions_ztest, proportion_effectsize
from statsmodels.stats.power import NormalIndPower
import math

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="ABå®éªŒå…¨åŠŸèƒ½æ•™å­¦æ²™ç›˜", layout="wide")


# --- æ ¸å¿ƒå“ˆå¸Œåˆ†æµç®—æ³• ---
def get_group(user_id, layer_name, salt):
    input_str = f"{user_id}_{layer_name}_{salt}"
    hash_val = int(hashlib.md5(input_str.encode()).hexdigest(), 16)
    return 'A' if (hash_val % 100) < 50 else 'B'


# --- æ ¸å¿ƒç®—æ³•ï¼šè´å¶æ–¯åˆ†æ ---
def run_bayesian_analysis(c_clicks, c_n, t_clicks, t_n):
    """
    ä½¿ç”¨ Beta åˆ†å¸ƒè¿›è¡Œè´å¶æ–¯åéªŒé‡‡æ ·
    è®¡ç®— B ç»„ä¼˜äº A ç»„çš„æ¦‚ç‡ä»¥åŠæœŸæœ›æŸå¤±
    """
    # é‡‡ç”¨æ— ä¿¡æ¯å…ˆéªŒ Beta(1,1)
    alpha_a, beta_a = 1 + c_clicks, 1 + c_n - c_clicks
    alpha_b, beta_b = 1 + t_clicks, 1 + t_n - t_clicks

    # æŠ½å– 20,000 ä¸ªæ ·æœ¬æ¨¡æ‹ŸåéªŒåˆ†å¸ƒ
    samples = 20000
    a_samples = np.random.beta(alpha_a, beta_a, samples)
    b_samples = np.random.beta(alpha_b, beta_b, samples)

    # è®¡ç®— B > A çš„é¢‘ç‡ä½œä¸ºæ¦‚ç‡
    prob_b_better = (b_samples > a_samples).mean()
    # è®¡ç®—æœŸæœ›æŸå¤±ï¼šå¦‚æœ B å®é™…æ¯” A å·®ï¼Œé€‰ B å¹³å‡ä¼šæŸå¤±å¤šå°‘è½¬åŒ–ç‡
    expected_loss = np.maximum(a_samples - b_samples, 0).mean()

    return prob_b_better, expected_loss


# --- ä¾§è¾¹æ ï¼šä¸Šå¸è§†è§’æ§åˆ¶ ---
with st.sidebar:
    st.header("ğŸ› ï¸ å®éªŒç¯å¢ƒé…ç½®")
    dau = st.number_input("æ—¥æ´»æµé‡ (DAU)", value=1000, step=100)
    base_p = st.slider("åŸºç¡€è½¬åŒ–ç‡ (Baseline)", 0.01, 0.50, 0.10)

    st.divider()
    st.header("ğŸ—ï¸ æ­£äº¤æ¶æ„")
    salt_1 = st.text_input("Layer 1 ç›å€¼", "UI_EXP")
    salt_2 = st.text_input("Layer 2 ç›å€¼", "ALG_EXP")

    st.divider()
    st.header("ğŸ‘ï¸ ä¸Šå¸è§†è§’ (çœŸç›¸)")
    true_lift = st.slider("è®¾å®šçš„çœŸå®æå‡", -0.20, 0.20, 0.05, help="è¿™æ˜¯åªæœ‰ä¸Šå¸çŸ¥é“çš„çœŸç›¸ã€‚")

# --- å¤´éƒ¨æ•™å­¦å¼•å…¥ ---
st.title("ğŸ§ª A/B å®éªŒå…¨åŠŸèƒ½æ²™ç›˜ï¼šä» P å€¼åˆ°è´å¶æ–¯")
st.markdown("""
æœ¬æ²™ç›˜èåˆäº†**é¢‘ç‡æ´¾æ˜¾è‘—æ€§**ä¸**è´å¶æ–¯å†³ç­–ä¿¡å¿ƒ**ã€‚
ä½ å¯ä»¥è§‚å¯Ÿåœ¨ä¸åŒæ ·æœ¬é‡ä¸‹ï¼Œä¸¤ç§ç»Ÿè®¡æµæ´¾å¦‚ä½•å¯¹åŒä¸€ç»„æ•°æ®ç»™å‡ºä¸åŒçš„è§£è¯»ã€‚
""")

# --- ç¬¬ä¸€é˜¶æ®µï¼šæ’æœŸé¢„æµ‹ (ä¿ç•™åŸé€»è¾‘) ---
st.header("ğŸ“… ç¬¬ä¸€é˜¶æ®µï¼šæ’æœŸé¢„æµ‹ (Planning)")
mde_target = st.slider("ç›®æ ‡çµæ•åº¦ (MDE %)", 0.01, 0.15, 0.05)

obj = NormalIndPower()
try:
    p2_mde = base_p * (1 + mde_target)
    es = proportion_effectsize(p2_mde, base_p)
    req_n_per_group = obj.solve_power(effect_size=es, alpha=0.05, power=0.8, ratio=1.0)
    req_n = math.ceil(req_n_per_group * 2)
    est_days = math.ceil(req_n / dau)

    col1, col2 = st.columns(2)
    with col1:
        st.metric("æ‰€éœ€æ€»æ ·æœ¬é‡", f"{req_n:,}")
        st.write(f"**æ•™å­¦ç‚¹ï¼š** ä¸ºäº†çœ‹å¾—æ¸… {mde_target:.1%} çš„å¾®å°æ”¹åŠ¨ï¼Œä½ éœ€è¦ç§¯ç´¯è¶³å¤Ÿçš„â€˜å…‰çº¿â€™ï¼ˆæ ·æœ¬ï¼‰ã€‚")
    with col2:
        st.metric("å»ºè®®å®éªŒæ—¶é•¿", f"{est_days} å¤©")
        st.write("**æ•™å­¦ç‚¹ï¼š** æå‰ç»“æŸå®éªŒä¼šå¤§å¹…å¢åŠ â€˜ç¬¬ä¸€ç±»é”™è¯¯â€™ï¼ˆè™šå‡æ˜¾è‘—ï¼‰çš„é£é™©ã€‚")
except:
    st.error("è®¡ç®—å¤±è´¥ï¼Œè¯·è°ƒæ•´å‚æ•°ã€‚")

# --- ç¬¬äºŒé˜¶æ®µï¼šAA å®éªŒè‡ªæ£€ (ä¿ç•™åŸé€»è¾‘) ---
st.divider()
st.header("ğŸ›¡ï¸ ç¬¬äºŒé˜¶æ®µï¼šAA å®éªŒ (System Check)")
if st.button("è¿è¡Œ AA å®éªŒè‡ªæ£€"):
    aa_n = min(req_n, 5000)
    aa_users = [{"ID": f"u_{i}", "G": get_group(f"u_{i}", "L1", salt_1)} for i in range(aa_n)]
    df_aa = pd.DataFrame(aa_users)
    df_aa['C'] = df_aa['G'].apply(lambda x: np.random.binomial(1, base_p))
    aa_res = df_aa.groupby('G')['C'].agg(['count', 'sum'])
    z_aa, p_aa = proportions_ztest(aa_res['sum'][::-1], aa_res['count'][::-1])

    if p_aa < 0.05:
        st.error(f"ğŸš¨ AAå¤±è´¥ (P={p_aa:.4f})ï¼šåˆ†æµå™¨ä¸å…¬å¹³ï¼æ­¤æ—¶ç»“è®ºä¸å¯ä¿¡ã€‚")
    else:
        st.success(f"âœ… AAé€šè¿‡ (P={p_aa:.4f})ï¼šåˆ†æµå…¬å¹³ï¼Œå®éªŒç¯å¢ƒçº¯å‡€ã€‚")

# --- ç¬¬ä¸‰é˜¶æ®µï¼šå®æ—¶è¿è¡Œä¸å®¡è®¡ ---
st.divider()
st.header("ğŸ“Š ç¬¬ä¸‰é˜¶æ®µï¼šå®æ—¶è¿è¡Œä¸åŒå¼•æ“å†³ç­–")
days_run = st.slider("å®éªŒå·²è¿è¡Œå¤©æ•°", 1, max(30, est_days + 7), min(7, est_days))
current_n = dau * days_run

# æ•°æ®æ¨¡æ‹Ÿ
user_data = []
for i in range(current_n):
    uid = f"user_{i}"
    g1 = get_group(uid, "L1", salt_1)
    user_data.append({"ID": uid, "G": g1})
df_ab = pd.DataFrame(user_data)
df_ab['Click'] = df_ab['G'].apply(lambda x: np.random.binomial(1, base_p * (1 + true_lift) if x == 'B' else base_p))

res = df_ab.groupby('G')['Click'].agg(['count', 'sum'])
ca_n, ca_s = res.loc['A', 'count'], res.loc['A', 'sum']
cb_n, cb_s = res.loc['B', 'count'], res.loc['B', 'sum']

# --- æ ¸å¿ƒï¼šé¢‘ç‡æ´¾ vs è´å¶æ–¯ å¯¹æ¯”é¢æ¿ ---
st.subheader("âš–ï¸ å†³ç­–åšå¼ˆï¼šè°æ›´å¯ä¿¡ï¼Ÿ")
col_freq, col_bayes = st.columns(2)

# é¢‘ç‡æ´¾è®¡ç®—
z, p_val = proportions_ztest([cb_s, ca_s], [cb_n, ca_n])
with col_freq:
    st.info("### é¢‘ç‡æ´¾ (Frequentist)")
    st.metric("P-value", f"{p_val:.4f}")
    if p_val < 0.05:
        st.success("âœ… ç»“è®ºæ˜¾è‘—ï¼å¯ä»¥æ‹’ç»åŸå‡è®¾ã€‚")
    else:
        st.error("âŒ ä¸æ˜¾è‘—ã€‚å·®å¼‚å¯èƒ½æ¥è‡ªéšæœºæ³¢åŠ¨ã€‚")
    st.write("**æ•™å­¦ç‚¹ï¼š** På€¼å›ç­”çš„æ˜¯â€˜æ„å¤–ç¨‹åº¦â€™ã€‚")

# è´å¶æ–¯æ´¾è®¡ç®—
prob_b_wins, exp_loss = run_bayesian_analysis(ca_s, ca_n, cb_s, cb_n)
with col_bayes:
    st.info("### è´å¶æ–¯æ´¾ (Bayesian)")
    st.metric("B ç»„èƒœå‡ºæ¦‚ç‡", f"{prob_b_wins:.2%}")
    st.metric("é€‰æ‹© B çš„é£é™© (æœŸæœ›æŸå¤±)", f"{exp_loss:.6f}")
    if prob_b_wins > 0.95:
        st.success("âœ… ä¿¡å¿ƒå……è¶³ï¼B ç»„å¤§æ¦‚ç‡çœŸçš„æ›´å¥½ã€‚")
    else:
        st.warning("âš ï¸ ä¿¡å¿ƒå°šæ—©ã€‚è™½ç„¶å¯èƒ½å ä¼˜ï¼Œä½†ä»æœ‰é£é™©ã€‚")
    st.write("**æ•™å­¦ç‚¹ï¼š** è´å¶æ–¯å›ç­”çš„æ˜¯â€˜ä¸‹æ³¨ä¿¡å¿ƒâ€™ã€‚")

# --- æ ¸å¿ƒï¼šå®¡è®¡è¯„åˆ† (ä¿ç•™å¹¶èå…¥è´å¶æ–¯æ¦‚å¿µ) ---
st.divider()
st.subheader("ğŸ›¡ï¸ å®éªŒå¯ä¿¡åº¦è´¨é‡å®¡è®¡")
try:
    raw_p = obj.power(effect_size=es, nobs1=current_n / 2, alpha=0.05, ratio=1.0)
    curr_power = float(raw_p.power) if hasattr(raw_p, 'power') else float(raw_p)
except:
    curr_power = 0.0

score = 0
audit_log = []
if current_n >= req_n:
    score += 40
    audit_log.append("âœ… **æ ·æœ¬å……è¶³**ï¼šå·²è·‘æ»¡æ’æœŸï¼Œè§„é¿äº†â€˜å·çœ‹é—®é¢˜â€™ã€‚")
else:
    audit_log.append(f"âŒ **æ ·æœ¬ä¸è¶³**ï¼šä»…å®Œæˆé¢„æµ‹é‡çš„ {current_n / req_n:.1%}ã€‚")

if curr_power >= 0.8:
    score += 30
    audit_log.append("âœ… **åŠŸæ•ˆå……è¶³**ï¼šæ¢æµ‹å™¨åŠŸç‡è¾¾æ ‡ï¼Œè§‚å¯Ÿå€¼è¶‹äºçœŸç›¸ã€‚")
else:
    audit_log.append(f"âŒ **ä½åŠŸæ•ˆè­¦å‘Š**ï¼šPower ä»… {curr_power:.1%}ã€‚å°å¿ƒâ€˜èµ¢å®¶è¯…å’’â€™ã€‚")

if p_val < 0.05:
    score += 30
    audit_log.append("âœ… **é¢‘ç‡æ´¾æ˜¾è‘—**ï¼šè¯æ®å¼ºåº¦è¾¾æ ‡ã€‚")

aud1, aud2 = st.columns([1, 2])
with aud1:
    st.metric("å®éªŒå¯ä¿¡åº¦æ€»åˆ†", f"{score}/100")
    if score == 100:
        st.success("ğŸ’ æé«˜å¯ä¿¡åº¦ï¼šç›´æ¥ä¸‹ç»“è®º")
    elif score >= 70:
        st.warning("âš ï¸ ä¸­åº¦å¯ä¿¡ï¼šå»ºè®®ç»“åˆä¸šåŠ¡é£é™©å†³ç­–")
    else:
        st.error("ğŸš« ä½å¯ä¿¡åº¦ï¼šæ‹’ç»å†³ç­–")

with aud2:
    for log in audit_log: st.write(log)

# æŒ‡æ ‡çœ‹æ¿
st.divider()
c1, c2, c3 = st.columns(3)
obs_lift = (cb_s / cb_n) / (ca_s / ca_n) - 1
c1.metric("è§‚å¯Ÿåˆ°çš„æå‡", f"{obs_lift:.2%}", delta=f"{(obs_lift - true_lift):.2%} (åç¦»çœŸå€¼)")
c2.metric("å½“å‰æ ·æœ¬æ€»é‡", f"{current_n:,}")
c3.metric("ç»Ÿè®¡åŠŸæ•ˆ (Power)", f"{curr_power:.2%}")

# --- æ•™å­¦ç¬”è®° (ä¿ç•™å¹¶æ–°å¢) ---
st.divider()
with st.expander("ğŸ“– å®éªŒèƒŒåçš„ç§‘å­¦é€»è¾‘ (æ•™å­¦å¿…è¯»)"):
    st.markdown("""
    1. **ç¬¬ä¸€/äºŒç±»é”™è¯¯**ï¼šAlpha æ˜¯â€œå’‹å‘¼â€ï¼ˆæ²¡æ•ˆè¯´æœ‰æ•ˆï¼‰ï¼ŒBeta æ˜¯â€œæœ¨è®·â€ï¼ˆæœ‰æ•ˆæ²¡æµ‹å‡ºæ¥ï¼‰ã€‚
    2. **èµ¢å®¶è¯…å’’**ï¼šåœ¨ Power æä½æ—¶ï¼Œå¦‚æœåˆšå¥½æ˜¾è‘—ï¼Œä½ çœ‹åˆ°çš„æå‡å¾€å¾€æ˜¯è¢«éšæœºè¯¯å·®å¤¸å¤§åçš„â€œè™šå‡ç¹è£â€ã€‚
    3. **é¢‘ç‡æ´¾ vs è´å¶æ–¯**ï¼š
        - **é¢‘ç‡æ´¾**æ›´ä¸¥è°¨ï¼Œåªæœ‰è¯æ®ç¡®å‡¿ï¼ˆP < 0.05ï¼‰æ‰è¯´è¯ã€‚
        - **è´å¶æ–¯**æ›´ç›´è§‚ï¼Œå®ƒå‘Šè¯‰ä½ â€œå¦‚æœä½ é€‰ Bï¼Œæœ‰å¤šå°‘æ¦‚ç‡ä¼šèµ¢ï¼Œå¦‚æœè¾“äº†ä¼šæŸå¤±å¤šå°‘â€ã€‚åœ¨å°æ ·æœ¬å†³ç­–æ—¶ï¼Œè´å¶æ–¯çš„â€œæœŸæœ›æŸå¤±â€æ¯” P å€¼æ›´æœ‰ä¸šåŠ¡æ„ä¹‰ã€‚
    4. **æ­£äº¤æ€§**ï¼šä¾é å“ˆå¸Œç›å€¼ï¼ˆSaltï¼‰é‡æ–°æ´—ç‰Œã€‚ä½ å¯ä»¥è¯•ç€ä¿®æ”¹å·¦ä¾§çš„ Layer 2 ç›å€¼ï¼Œè§‚å¯Ÿå®ƒæ˜¯å¦å¹²æ‰°äº† Layer 1 çš„ç»“æœã€‚
    """)